{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- Implement in Python a\n",
    "logistic regression model using a SMS Spam\n",
    "Collection Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # for ignoring the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset into a Dataframe\n",
    "df = pd.read_csv('dataset.csv' , encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMPROVING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing useless columns\n",
    "df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis=1, inplace=True)\n",
    "# Renaming the useful columns\n",
    "df = df.rename(columns={'v1':'label','v2':'message'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label mapping as ham -> 0 , spam -> 1\n",
    "df['label_num'] = df['label'].map({'ham':0 , 'spam':1})\n",
    "# Adding a new Length column\n",
    "df['Length'] = df['message'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VISUALISING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of spam and ham messages\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a count Plot of label column\n",
    "sns.countplot(df['label'], palette=sns.color_palette('Set2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a count Plot of Length column\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.countplot(df['Length'], palette=sns.color_palette('Set2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Length of a message is\", round(df['Length'].mean()))\n",
    "print(\"Standard deviation of length is\", round(df['Length'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution and Mean length of spam messages\n",
    "spam_len = df.loc[df[\"label_num\"] == 1, \"Length\"]\n",
    "plt.figure(figsize=(14,8))\n",
    "sns.countplot(spam_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Length of a text of spam message is\", round(spam_len.mean()))\n",
    "print(\"Standard deviation of length of spam message is\", round(spam_len.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution and Mean length of ham messages\n",
    "ham_len = df.loc[df[\"label_num\"] == 0, \"Length\"]\n",
    "plt.figure(figsize=(14,8))\n",
    "sns.countplot(ham_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Length of a text of ham message is\", round(ham_len.mean()))\n",
    "print(\"Standard deviation of length of ham message is\", round(ham_len.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above visualisation and data gives the proof of the fact that spam messages are long and the difference between their size is very small\n",
    "And for the ham messages, average length is comparitively small and standard deviation is huge, as we know some ham messages are big , some are small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOW PREPROCESSING THE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuation\n",
    "def rem_punc(text):\n",
    "    new_text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return new_text\n",
    "df['message'] = df['message'].apply(lambda x: rem_punc(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower Case\n",
    "df['message'] = df['message'].apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SPLITTING THE TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=24)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "train_df.to_csv('train_data.csv')\n",
    "test_df.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe -> array\n",
    "xtrain, ytrain = np.asanyarray(train_df['message']), np.asanyarray(train_df['label_num'])\n",
    "xtest, ytest = np.asanyarray(test_df['message']), np.asanyarray(test_df['label_num'])\n",
    "len(xtrain), len(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use \"CountVectorizer()\" to transform a xtrain text data into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\n",
    "# It is something like each term is assigned a weight based on how many times it appears in spam and ham messages. For instance, if “win big money prize” is one of our features and only appears in spam emails, then it will be given a larger probability of being spam.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "counter_vec = CountVectorizer().fit(xtrain)\n",
    "xtrain_vec, xtest_vec = counter_vec.transform(xtrain), counter_vec.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model.fit(xtrain_vec,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = LR_model.predict(xtest_vec)\n",
    "# Comparing original test results with predicted results\n",
    "print(ypred[:100])\n",
    "print(ytest[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excep_count=0\n",
    "for i,j in zip(ytest,ypred):\n",
    "    if i!=j:\n",
    "        excep_count=excep_count+1\n",
    "print(\"Only\",excep_count, \"wrong predictions among\", len(ytest),\"test data\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = round(accuracy_score(ytest,ypred) * 100 , 2)\n",
    "print(\"Accuracy of the Model is : \", score, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREDICTING BY GIVING A CUSTOM INPUT MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmessage = input()\n",
    "lst=[]\n",
    "lst.append(inmessage)\n",
    "indf = pd.DataFrame(lst, columns=['in'])\n",
    "intest = np.asanyarray(indf['in'])\n",
    "intest_vec = counter_vec.transform(intest)\n",
    "predlab = LR_model.predict(intest_vec)\n",
    "if predlab[0]==1:\n",
    "    print(\"this is a spam message !!!\")\n",
    "else:\n",
    "    print(\"this is a ham message.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70ce6fb985c8da0c869caeaf7084345036ef7b252baf67cd96a8f14658dc9ee6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
